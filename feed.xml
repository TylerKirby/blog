<?xml version="1.0" encoding="utf-8"?><feed xmlns="http://www.w3.org/2005/Atom" ><generator uri="https://jekyllrb.com/" version="4.1.1">Jekyll</generator><link href="https://jtylerkirby.com/feed.xml" rel="self" type="application/atom+xml" /><link href="https://jtylerkirby.com/" rel="alternate" type="text/html" /><updated>2022-05-15T17:02:44-05:00</updated><id>https://jtylerkirby.com/feed.xml</id><title type="html">J. Tyler Kirby</title><subtitle>Personal writings on machine learning, math, classics etc.</subtitle><entry><title type="html">The Basics of Bayesian Machine Learning</title><link href="https://jtylerkirby.com/machine_learning/2021/01/20/Basics-Bayes-ML.html" rel="alternate" type="text/html" title="The Basics of Bayesian Machine Learning" /><published>2021-01-20T00:00:00-06:00</published><updated>2021-01-20T00:00:00-06:00</updated><id>https://jtylerkirby.com/machine_learning/2021/01/20/-Basics-Bayes-ML</id><author><name></name></author><category term="machine_learning" /><summary type="html"><![CDATA[Bayesian methods can offer capabilities like uncertainty estimates and encoding domain knowledge directly into a model. This post provides an overview of Bayesian methods beginning with a review of probability before showing how it can be applied to the coin flipping problem. By the end, the reader will have a basic understanding of the methods and where to go from here.]]></summary></entry></feed>